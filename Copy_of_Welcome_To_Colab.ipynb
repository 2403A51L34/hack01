{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403A51L34/hack01/blob/main/Copy_of_Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# smart_health_pipeline.py\n",
        "# Easy, robust pipeline for early warning using your uploaded CSV.\n",
        "# Edit `cases_col` below to the exact column name if auto-detection fails.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "\n",
        "# ---------- Configuration ----------\n",
        "DATA_DIR = Path(\"/content/\")\n",
        "ZIP_NAME = \"archive (2).zip\"   # the uploaded zip\n",
        "EXTRACT_DIR = DATA_DIR / \"extracted_dataset\"\n",
        "EXTRACT_DIR.mkdir(exist_ok=True)\n",
        "# If your dataset has a known cases column, set it explicitly:\n",
        "# e.g. cases_col = \"Number of cases per 100,000 people\"\n",
        "cases_col_override = None\n",
        "# ---------- End configuration ----------\n",
        "\n",
        "zip_path = DATA_DIR / ZIP_NAME\n",
        "if not zip_path.exists():\n",
        "    # fallback: look for CSVs directly in /mnt/data\n",
        "    csvs = list(DATA_DIR.glob(\"*.csv\"))\n",
        "    if not csvs:\n",
        "        raise FileNotFoundError(f\"Could not find {ZIP_NAME} or any CSV in {DATA_DIR}.\")\n",
        "    csv_path = csvs[0]\n",
        "else:\n",
        "    # extract CSVs inside zip\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        csvs_in_zip = [f for f in z.namelist() if f.lower().endswith('.csv')]\n",
        "        if not csvs_in_zip:\n",
        "            raise FileNotFoundError(\"No CSV files found inside the zip.\")\n",
        "        # extract first CSV\n",
        "        z.extract(csvs_in_zip[0], path=EXTRACT_DIR)\n",
        "        csv_path = EXTRACT_DIR / csvs_in_zip[0]\n",
        "\n",
        "print(\"Using CSV:\", csv_path)\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Loaded shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# detect a cases-like column (unless user overrode)\n",
        "cases_col = None\n",
        "if cases_col_override:\n",
        "    if cases_col_override in df.columns:\n",
        "        cases_col = cases_col_override\n",
        "    else:\n",
        "        raise ValueError(f\"cases_col_override '{cases_col_override}' not found in columns.\")\n",
        "else:\n",
        "    # common names to check\n",
        "    candidates = [\"cases\", \"case_count\", \"count\", \"cases_reported\", \"patients\", \"no_of_cases\", \"num_cases\",\n",
        "                  \"cases_per_100000\", \"cases per 100000\", \"number of cases\"]\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            cases_col = c\n",
        "            break\n",
        "    if cases_col is None:\n",
        "        # fallback heuristic: look for any column name containing 'case' or 'count' or 'patient'\n",
        "        for col in df.columns:\n",
        "            if any(k in col.lower() for k in [\"case\", \"count\", \"patient\"]):\n",
        "                cases_col = col\n",
        "                break\n",
        "\n",
        "if cases_col is None:\n",
        "    print(\"WARNING: No clear cases/count column detected. You should set `cases_col_override` to the correct column name.\")\n",
        "    # Still continue: create a numeric dummy column (will be zeros) to keep pipeline safe\n",
        "    df['cases_numeric'] = 0\n",
        "else:\n",
        "    df['cases_numeric'] = pd.to_numeric(df[cases_col], errors='coerce').fillna(0)\n",
        "    print(\"Using cases column:\", cases_col)\n",
        "\n",
        "# define outbreak threshold (75th percentile)\n",
        "threshold = float(np.percentile(df['cases_numeric'], 75))\n",
        "print(\"Outbreak threshold (75th percentile):\", threshold)\n",
        "\n",
        "# features: simple lags and rolling mean (works without time index)\n",
        "for lag in [1, 3, 7]:\n",
        "    df[f'lag_{lag}'] = df['cases_numeric'].shift(lag).fillna(method='bfill')\n",
        "df['rolling_mean_7'] = df['cases_numeric'].rolling(window=7, min_periods=1).mean().fillna(method='bfill')\n",
        "\n",
        "# include any numeric environmental columns we can guess (rain, temp, water, ph)\n",
        "env_candidates = [c for c in df.columns if any(k in c.lower() for k in ['rain', 'temp', 'water', 'ph', 'quality', 'turbidity', 'chlorine'])]\n",
        "for c in env_candidates:\n",
        "    df[c + '_num'] = pd.to_numeric(df[c], errors='coerce').fillna(0)\n",
        "\n",
        "feature_cols = [c for c in df.columns if c.startswith('lag_') or c.startswith('rolling_') or c.endswith('_num')]\n",
        "print(\"Feature columns:\", feature_cols)\n",
        "\n",
        "X = df[feature_cols].fillna(0)\n",
        "# create outbreak label if possible\n",
        "outbreak_present = (df['cases_numeric'].nunique() > 1)\n",
        "if outbreak_present:\n",
        "    df['outbreak'] = (df['cases_numeric'] > threshold).astype(int)\n",
        "    y = df['outbreak']\n",
        "else:\n",
        "    # All-zero or single-value cases => no binary outbreak possible\n",
        "    y = None\n",
        "\n",
        "# Train & evaluate\n",
        "if y is None or y.nunique() < 2:\n",
        "    print(\"No binary outbreak target available. Falling back to regression to predict case counts.\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df['cases_numeric'], test_size=0.2, random_state=42)\n",
        "    reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    reg.fit(X_train, y_train)\n",
        "    preds = reg.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    rmse = mean_squared_error(y_test, preds) # Removed squared=False\n",
        "    print(\"Regression MAE:\", mae, \"RMSE:\", rmse)\n",
        "    # flag predictions above threshold as alerts\n",
        "    alerts = X_test.copy()\n",
        "    alerts['pred_cases'] = preds\n",
        "    alerts['pred_alert'] = (alerts['pred_cases'] > threshold).astype(int)\n",
        "    alerts['actual_cases'] = y_test.values\n",
        "    # Save regressor\n",
        "    joblib.dump({'regressor': reg, 'features': feature_cols, 'threshold': threshold}, DATA_DIR / \"outbreak_regressor.joblib\")\n",
        "    print(\"Saved regressor to:\", DATA_DIR / \"outbreak_regressor.joblib\")\n",
        "    # Show top predicted alerts\n",
        "    print(\"Top predicted alerts (by predicted cases):\")\n",
        "    print(alerts.sort_values('pred_cases', ascending=False).head(10))\n",
        "else:\n",
        "    print(\"Binary outbreak target available. Running classification.\")\n",
        "    df['outbreak'] = (df['cases_numeric'] > threshold).astype(int)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df['outbreak'], test_size=0.2, random_state=42, stratify=df['outbreak'])\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    # safe probability extraction\n",
        "    if hasattr(clf, \"predict_proba\") and getattr(clf, \"n_classes_\", None) and clf.n_classes_ > 1:\n",
        "        proba = clf.predict_proba(X_test)[:,1]\n",
        "    else:\n",
        "        proba = preds.astype(float)  # fallback\n",
        "    print(\"Classification report:\")\n",
        "    print(classification_report(y_test, preds, zero_division=0))\n",
        "    try:\n",
        "        print(\"ROC AUC:\", roc_auc_score(y_test, proba))\n",
        "    except Exception:\n",
        "        print(\"ROC AUC not available for this split.\")\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "    joblib.dump({'model': clf, 'features': feature_cols, 'threshold': threshold}, DATA_DIR / \"outbreak_classifier.joblib\")\n",
        "    print(\"Saved classifier to:\", DATA_DIR / \"outbreak_classifier.joblib\")\n",
        "    alerts = X_test.copy()\n",
        "    alerts['pred_proba'] = proba\n",
        "    alerts['pred_outbreak'] = (alerts['pred_proba'] > 0.5).astype(int)\n",
        "    alerts['actual_outbreak'] = y_test.values\n",
        "    print(\"Top predicted outbreak probabilities:\")\n",
        "    print(alerts.sort_values('pred_proba', ascending=False).head(10))\n",
        "\n",
        "print(\"Pipeline finished. Adjust 'cases_col_override' to point to the correct case-count column to enable classification-mode outbreak warnings.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW8BYQLbdtfh",
        "outputId": "0bc2983c-6709-403e-88a7-9b1d94166674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Could not find archive (2).zip or any CSV in /content.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3061710272.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcsvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcsvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not find {ZIP_NAME} or any CSV in {DATA_DIR}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Could not find archive (2).zip or any CSV in /content."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}